{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5bdf6dc-3ed2-4e70-a6ef-080c0e5c0408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/efs/fs1/miniconda3/envs/gml/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f66721fd-ba3f-4665-a595-a91cfedf0368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import pickle\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5f45dd-00ea-4d1d-9d8b-da7242281738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a623f3f-64b5-4843-a579-5cecfdf5ba18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7ee01b8530>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4591bc95-71a6-4472-8a6c-2ff4c0798522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model: Any, model_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Saves model in gzip format\n",
    "\n",
    "    Args:\n",
    "        model: Model to be saved\n",
    "        model_path: Path to save model to\n",
    "        \n",
    "    Returns:\n",
    "        (None)\n",
    "    \"\"\"\n",
    "    import gzip\n",
    "    with gzip.open(model_path, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    print(f'Model saved to {model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee658bc-dc25-4697-90d5-3057ff4b92fd",
   "metadata": {},
   "source": [
    "## Create the MF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80a81f20-efd4-4fbc-ba13-d9dc55ace4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularize_l2(array):\n",
    "    loss = torch.sum(array ** 2)\n",
    "    return loss\n",
    "\n",
    "class MF(nn.Module):\n",
    "    def __init__(self, emb_size, emb_dim, c_vector=1e-6):\n",
    "        super().__init__()\n",
    "        self.emb_size = emb_size # size of the dictionary of embeddings\n",
    "        self.emb_dim = emb_dim # size of each embedding vector\n",
    "        self.c_vector = c_vector\n",
    "        \n",
    "        # layers\n",
    "        self.embedding = nn.Embedding(emb_size, emb_dim)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "        # loss\n",
    "        self.bce = nn.BCELoss()\n",
    "        \n",
    "        print(f'Model initialized: {self}')\n",
    "        \n",
    "    def forward(self, product1, product2):\n",
    "        emb_product1 = self.embedding(product1)\n",
    "        emb_product2 = self.embedding(product2)\n",
    "        interaction = self.sig(torch.sum(emb_product1*emb_product2, dim = 1, dtype = torch.float))\n",
    "        return interaction\n",
    "    \n",
    "    \n",
    "    def loss(self, pred, label):\n",
    "        mf_loss = self.bce(pred, label)\n",
    "        \n",
    "        # L2 regularization\n",
    "        product_prior = refularize_l2(self.embedding.weight) * self.c_vector\n",
    "        \n",
    "        loss_total  = mf_loss + product_prior # loss + regularization \n",
    "        \n",
    "        return loss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee543547-3620-4d69-8095-f79c8ab0a921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized: MF(\n",
      "  (embedding): Embedding(1000, 12)\n",
      "  (sig): Sigmoid()\n",
      "  (bce): BCELoss()\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MF(\n",
       "  (embedding): Embedding(1000, 12)\n",
       "  (sig): Sigmoid()\n",
       "  (bce): BCELoss()\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MF(1000, 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e02dedf-e5f2-459f-b72b-8ace2e121bd2",
   "metadata": {},
   "source": [
    "## Create the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63746617-ea27-42c8-b6a8-146c12600746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from collections import Counter\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6431177d-1b9d-4a1c-bad2-471b1230ee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0aaf16eb-a916-4d36-a440-a084f7077c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequences:\n",
    "    NEGATIVE_SAMPLE_TABLE_SIZE = 1e7\n",
    "    WINDOW = 5\n",
    "    \n",
    "    def __init__(self, sequence_path: str, val_path: str, subsample: float = 0.001, power: float = 0.75):\n",
    "        \"\"\"\n",
    "        Intialize the dataset object\n",
    "        \"\"\"\n",
    "        self.negative_idx = 0\n",
    "        self.n_unique_tokens = 0\n",
    "        \n",
    "        self.sequences = np.load(sequence_path).tolist()\n",
    "        self.n_sequences = len(self.sequences)\n",
    "        print(f'# Sequences = {self.n_sequences}')\n",
    "        \n",
    "        self.val = pd.read_csv(val_path)\n",
    "        print(f'# Validation data = {self.val.shape}')\n",
    "        \n",
    "        self.word_freq = self.get_word_freq()\n",
    "        \n",
    "        self.word2id, self.id2word = self.get_mapping_dicts()\n",
    "        self.add_val_product_to_mapping_dicts()\n",
    "        self.n_unique_tokens = len(self.word2id)\n",
    "        print(f'# Tokens = {self.n_unique_tokens}')\n",
    "        \n",
    "        sequence_file_name = Path(sequence_path).resolve().stem\n",
    "        save_model(self.word2id, f'../data/processed/{sequence_file_name}_word2id')\n",
    "        save_model(self.id2word, f'../data/processed/{sequence_file_name}_id2word')\n",
    "        \n",
    "        self.sequences = self.convert_sequence_to_id()\n",
    "        self.word_freq = self.convert_word_freq_to_id()\n",
    "        \n",
    "        self.discard_probs = self.get_discard_probs(sample = subsample)\n",
    "        \n",
    "        self.neg_table = self.get_negative_sample_table(power = power)\n",
    "        \n",
    "    def get_word_freq(self) -> Counter:\n",
    "        \"\"\"\n",
    "        Returns a dictionary of word frequencies\n",
    "        \"\"\"\n",
    "        \n",
    "        seq_flat = list(itertools.chain.from_iterable(self.sequences)) # flatten the array\n",
    "        \n",
    "        word_freq = Counter(seq_flat)\n",
    "        \n",
    "        return word_freq\n",
    "    \n",
    "    def get_mapping_dicts(self):\n",
    "        word2id = dict()\n",
    "        id2word = dict()\n",
    "        \n",
    "        wid = 0\n",
    "        for w,c in self.word_freq.items():\n",
    "            word2id[w] = wid\n",
    "            id2word[wid] = w\n",
    "            wid += 1\n",
    "        \n",
    "        return word2id, id2word\n",
    "    \n",
    "    def add_val_product_to_mapping_dicts(self):\n",
    "        val_product_set = set(self.val['product1'].values).union(set(self.val['product2'].values))\n",
    "        \n",
    "        print(f'Size of word2id before adding val product : {len(self.word2id)}')\n",
    "        wid = max(self.word2id.values()) + 1\n",
    "        for w in val_product_set:\n",
    "            if w in self.word2id:\n",
    "                self.word2id[w] = wid\n",
    "                self.id2word[wid] = w\n",
    "                wid +=1\n",
    "        \n",
    "        self.val = None # free up space\n",
    "        print(f'Size of the word2id after adding val product : {len(self.word2id)}')\n",
    "        \n",
    "                \n",
    "    def convert_sequence_to_id(self):\n",
    "        return np.vectorize(self.word2id.get)(self.sequences)\n",
    "    \n",
    "    def get_product_id(self, x):\n",
    "        return self.word2id.get(x, -1)\n",
    "    \n",
    "    def convert_word_freq_to_id(self):\n",
    "        return {self.word2id[k] : v for k ,v  in self.word_freq.items()}\n",
    "    \n",
    "    def get_discard_probs(self, sample = 0.001):\n",
    "        \"\"\"\n",
    "        Returns a dictionary of words and their associated discard probability, \n",
    "        word should ne discarded if np.random.rand() < probability\n",
    "        \"\"\"\n",
    "        \n",
    "        # convert to array\n",
    "        word_freq = np.array(list(self.word_freq.items()), dtype=np.float64)\n",
    "        \n",
    "        # convert to probability\n",
    "        word_freq[:, 1] = word_freq[:, 1] / word_freq[:, 1].sum()\n",
    "        \n",
    "        # perform subsampling \n",
    "        # http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/\n",
    "        word_freq[:, 1] = (np.sqrt(word_freq[:, 1]/ sample) + 1) * (sample / word_freq[:, 1]) \n",
    "        \n",
    "        # get dict \n",
    "        discard_probs = {int(k) : v for k, v in word_freq.tolist()}\n",
    "        \n",
    "        return discard_probs\n",
    "    \n",
    "    def get_negative_sample_table(self, power=0.75):\n",
    "        \"\"\"\n",
    "        Returns a table with size = NEGATIVE_SAMPLE_TABLE_SIZE of nagative samples which can be selected via indexing. \n",
    "        \"\"\"\n",
    "        \n",
    "        # COnvert to array \n",
    "        word_freq = np.array(list(self.word_freq.items()), dtype = np.float)\n",
    "        \n",
    "        # adjust the power\n",
    "        word_freq[:, 1] = word_freq[:, 1] ** power\n",
    "        \n",
    "        # Get probabilities\n",
    "        word_freq_sum = word_freq[:, 1] ** power\n",
    "        word_freq[:, 1] = word_freq[:, 1] / word_freq_sum\n",
    "        \n",
    "        # Multiply probabilities by sample table size\n",
    "        word_freq[:, 1] = np.round(word_freq[:, 1] * self.NEGATIVE_SAMPLE_TABLE_SIZE)\n",
    "        \n",
    "        # Convert to int \n",
    "        word_freq = word_freq.astype(int).tolist()\n",
    "        \n",
    "        # create the sample table\n",
    "        sample_table = [[tup[0]]*tup[1] for tup in word_freq] # repeating the index (wrod_id) by proportion of their frequency (more frequent words are more probable for sampling)\n",
    "        sample_table = np.array(list(itertools.chain.from_iterable(sample_table)))\n",
    "        np.random.shuffle(sample_table)\n",
    "\n",
    "        return sample_table\n",
    "        \n",
    "    \n",
    "    def get_pairs(self, idx, window = 5):\n",
    "        pairs = []\n",
    "        sequence = self.sequences[idx]\n",
    "        \n",
    "        for center_idx, node in enumerate(sequence):\n",
    "            for i in range(-window, window + 1):\n",
    "                context_idx = center_idx + i\n",
    "                if (context_idx > 0) and (context_idx < len(sequence)) and (node != sequence[context_idx]) and (np.random.rand() < self.discard_probs[sequence[context_idx]]):\n",
    "                    pairs.append((node, sequence[context_idx]))\n",
    "    \n",
    "        \n",
    "        return pairs\n",
    "    \n",
    "    def get_all_center_context_pair(self, window = 5) -> List[Tuple[int, int]]:\n",
    "        \"\"\"\n",
    "        Returns a list of tuples (center, context).\n",
    "        \n",
    "        Args: \n",
    "            window:\n",
    "            \n",
    "        Returns:\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        pairs = []\n",
    "        \n",
    "        for sequence in self.sequences:\n",
    "            for center_idx, node in enumerate(sequence):\n",
    "                context_idx = center_idx + i\n",
    "                if (0 <= context_idx < len(sequence)) \\\n",
    "                    and node != sequence[context_idx] \\\n",
    "                    and np.random.rand() < self.discard_probs[sequence[context_idx]]:\n",
    "                    pairs.append((node, sequence[context_idx]))\n",
    "                        \n",
    "            \n",
    "        return pairs\n",
    "    \n",
    "    \n",
    "    def get_negative_samples(self, context, sample_size = 5) -> np.array:\n",
    "        \"\"\"\n",
    "        Returns a list of negative samples, where len = sample_size.\n",
    "        \n",
    "        Args:\n",
    "        \n",
    "            sample_size:\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        while True:\n",
    "            neg_sample = self.neg_table[self.negative_idx:self.negative_idx + sample_size]\n",
    "            \n",
    "            self.negative_idx = (self.negative_idx + sample_size) % len(self.neg_table)\n",
    "            \n",
    "            if len(neg_sample) != sample_size:\n",
    "                neg_sample = np.concatenate((neg_sample, \n",
    "                                             self.neg_table[:self.negative_idx]))\n",
    "                \n",
    "            \n",
    "            if not context in neg_sample:\n",
    "                return neg_sample    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd20f59d-8a87-4127-8514-965228b22d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequencesDataset(Dataset):\n",
    "    def __init__(self, sequences: Sequences, neg_sample_size = 5):\n",
    "        self.sequences = sequences\n",
    "        self.neg_sample_size = neg_sample_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.sequences.n_sequences\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        pairs = self.sequences.get_pairs(idx)\n",
    "        neg_samples = []\n",
    "        for center, context in pairs:\n",
    "            neg_samples.append(self.sequences.get_negative_samples(context))\n",
    "        \n",
    "        return pairs, neg_samples\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate(batches):\n",
    "        pairs_batch = [batch[0] for batch in batches]\n",
    "        neg_contexts_batch = [batch[1] for batch in batches]\n",
    "        \n",
    "        pairs_batch = list(itertools.chain.from_iterable(pairs_batch))\n",
    "        neg_contexts = list(itertools.chain.from_iterable(neg_contexts_batch))\n",
    "        \n",
    "        centers = [center for center, _ in pairs_batch]\n",
    "        contexts = [context for _, context in pairs_batch]\n",
    "        \n",
    "        return torch.LongTensor(centers), torch.LongTensor(contexts), torch.LongTensor(neg_contexts)\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate_for_mf(batches):\n",
    "        batch_list = []\n",
    "        \n",
    "        for batch in batches:\n",
    "            pairs = np.array(batch[0])\n",
    "            negs = np.array(batch[1])\n",
    "            negs = np.vstack((pairs[:, 0].repeat(negs.shape[1]), negs.ravel())).T\n",
    "            \n",
    "            pairs_arr = np.ones((pairs.shape[0], pairs.shape[1] + 1), dtype=int) # 2d\n",
    "            pairs_arr[:, :-1] = pairs\n",
    "            \n",
    "            negs_arr = mp.zeros((negs.shape[0], negs.shape[1] + 1), dtype=int) # 2d\n",
    "            negs_arr[:, :-1] = negs\n",
    "            \n",
    "            all_arr = np.vstack((pairs, negs_arr)) # 2d\n",
    "            batch_list.append(all_arr)\n",
    "            \n",
    "        batch_array = np.vstack(batch_list)\n",
    "        \n",
    "        \n",
    "        return (torch.LongTensor(batch_array[:, 0]),torch.LongTensor(batch_array[:, 1]),\n",
    "                torch.LongTensor(batch_array[:, 2]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d472d0-1a51-4e16-a5fa-b5c0076679cf",
   "metadata": {},
   "source": [
    "## Testing DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be9c1a5b-d337-466a-b6b9-a6f85a3398d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_path = '../data/processed/meta_Electronics_random_walks.npy'\n",
    "val_path = '../data/interim/meta_Electronics_edges_val.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "21cbe9d3-2b28-4640-acd3-bd9229f8d3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle = True\n",
    "emb_dim = 128\n",
    "epochs = 5\n",
    "initial_lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afbf2a5d-1ead-4fbb-a823-3e7eef303720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Sequences = 4649780\n",
      "# Validation data = (1440998, 3)\n",
      "Size of word2id before adding val product : 464978\n",
      "Size of the word2id after adding val product : 464978\n",
      "# Tokens = 464978\n",
      "Model saved to ../data/processed/meta_Electronics_random_walks_word2id\n",
      "Model saved to ../data/processed/meta_Electronics_random_walks_id2word\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10208/157408170.py:111: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  word_freq = np.array(list(self.word_freq.items()), dtype = np.float)\n"
     ]
    }
   ],
   "source": [
    "sequences = Sequences(read_path, val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2716db26-d43d-4e46-a4a1-794344fd0c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences.word_freq[sequences.word2id['b00f37z8q6']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "663e825f-8ce7-48c6-b773-7524b7a30b35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = SequencesDataset(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "947e68c4-0e82-4775-b885-690d40c0de4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size = 16, shuffle = shuffle, num_workers = 16, collate_fn = dataset.collate_for_mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fa4f0aac-339c-4a6c-a70e-3d72f9a10797",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(512542, 521805),\n",
       "  (512542, 621400),\n",
       "  (512542, 507254),\n",
       "  (512542, 668318),\n",
       "  (512542, 507254),\n",
       "  (521805, 621400),\n",
       "  (521805, 507254),\n",
       "  (521805, 668318),\n",
       "  (521805, 507254),\n",
       "  (521805, 628220),\n",
       "  (621400, 521805),\n",
       "  (621400, 507254),\n",
       "  (621400, 668318),\n",
       "  (621400, 507254),\n",
       "  (621400, 628220),\n",
       "  (621400, 614492),\n",
       "  (507254, 521805),\n",
       "  (507254, 621400),\n",
       "  (507254, 668318),\n",
       "  (507254, 628220),\n",
       "  (507254, 614492),\n",
       "  (507254, 628220),\n",
       "  (668318, 521805),\n",
       "  (668318, 621400),\n",
       "  (668318, 507254),\n",
       "  (668318, 507254),\n",
       "  (668318, 628220),\n",
       "  (668318, 614492),\n",
       "  (668318, 628220),\n",
       "  (668318, 474220),\n",
       "  (507254, 521805),\n",
       "  (507254, 621400),\n",
       "  (507254, 668318),\n",
       "  (507254, 628220),\n",
       "  (507254, 614492),\n",
       "  (507254, 628220),\n",
       "  (507254, 474220),\n",
       "  (628220, 521805),\n",
       "  (628220, 621400),\n",
       "  (628220, 507254),\n",
       "  (628220, 668318),\n",
       "  (628220, 507254),\n",
       "  (628220, 614492),\n",
       "  (628220, 474220),\n",
       "  (614492, 621400),\n",
       "  (614492, 507254),\n",
       "  (614492, 668318),\n",
       "  (614492, 507254),\n",
       "  (614492, 628220),\n",
       "  (614492, 628220),\n",
       "  (614492, 474220),\n",
       "  (628220, 507254),\n",
       "  (628220, 668318),\n",
       "  (628220, 507254),\n",
       "  (628220, 614492),\n",
       "  (628220, 474220),\n",
       "  (474220, 668318),\n",
       "  (474220, 507254),\n",
       "  (474220, 628220),\n",
       "  (474220, 614492),\n",
       "  (474220, 628220)],\n",
       " [array([ 9667099640000, 16620104498564,  5314177629899, 12703216551470,\n",
       "          6047870587749]),\n",
       "  array([ 2824235290767,  6879937434795,  9946685266602,  8645084043264,\n",
       "         18330184852836]),\n",
       "  array([13039878169680, 10964818572076,  8241483970716,  8263952250408,\n",
       "         12039927138834]),\n",
       "  array([10175539655146,  7802829382404, 14184735937815, 19222757493800,\n",
       "         15227828170633]),\n",
       "  array([ 7361493680646,  7107025168524, 11736693655240,  4372248349184,\n",
       "         17719980796188]),\n",
       "  array([ 3931431819471, 12942926641047,  2273292605056,  7478961662164,\n",
       "          6525667134048]),\n",
       "  array([ 7399738833420, 12180385127064, 12114566076976,  5242451628336,\n",
       "         10445617475200]),\n",
       "  array([ 6480885597636,  1799047394016,  7489886820570, 10540538075151,\n",
       "         12706359378880]),\n",
       "  array([12104059922958,  1813746755919,  6633791047464,  6675910155456,\n",
       "         13564520898450]),\n",
       "  array([ 4608398357332, 11674090881600,  8498808718855, 17529572058342,\n",
       "           130024788837]),\n",
       "  array([16287952972916, 17094983156570,  7174919981621, 12568923873084,\n",
       "          7015289786610]),\n",
       "  array([13821657969252, 13615489747384,  6217963286370, 13451020242890,\n",
       "         18429106699498]),\n",
       "  array([16629751110036, 13899579181768, 10381125762904, 19399528917120,\n",
       "         13520877133100]),\n",
       "  array([ 7652677763979,  8763587532630,  9256957565616,  6156257191632,\n",
       "         11702846957056]),\n",
       "  array([ 2846928608868, 12352326107365,  2897728994400,  1344029344878,\n",
       "         10575153706502]),\n",
       "  array([ 9343386289224, 13927508357262, 10671785936580,  6630164173050,\n",
       "          9175723600428]),\n",
       "  array([ 6833747526729, 21773205092578,  8021755387516, 11811820231750,\n",
       "          7567935747203]),\n",
       "  array([16852408187976,  3907669053960,  6211279307776, 11895949352388,\n",
       "         14992219300950]),\n",
       "  array([ 6689488636985,  4195637727996, 11929637596051, 10219320699048,\n",
       "         14019616561660]),\n",
       "  array([ 4740277942970, 18075178313958, 10552384126845, 15622352784160,\n",
       "          6966343484646]),\n",
       "  array([10461789863746,  5306916736632, 19328842765169,  7774443000942,\n",
       "         10515679050504]),\n",
       "  array([ 7450290716832, 12261231109071, 10026991964547,  1071204870424,\n",
       "          3733193523108]),\n",
       "  array([12959453521920,  7960936911348, 13585741610688, 11506142329770,\n",
       "         18400290007236]),\n",
       "  array([5950173529200, 9085099424842, 9313247502414, 5206315039422,\n",
       "         7342434785272]),\n",
       "  array([ 4154870279784,  9085864114166,  4644810484569, 18637072391523,\n",
       "          2219176145784]),\n",
       "  array([4941903081962, 7425865943496, 6255701954396, 4373201398053,\n",
       "         6926613710336]),\n",
       "  array([ 6358511881810,  7506996450723,  3181373432073,  5286867018532,\n",
       "         11023542992384]),\n",
       "  array([ 1768601785568, 11348452628292,  8924879825056, 12784115523912,\n",
       "         11758839850089]),\n",
       "  array([ 7923962181603,  1569536239194,  7503920734008, 15403784930079,\n",
       "          8568440885340]),\n",
       "  array([ 4597467536696,  4257916751924, 11934977390238, 13311260527600,\n",
       "          3209743429542]),\n",
       "  array([7172405916854, 6836962733737, 3525220892045, 7792132896891,\n",
       "         7836835179730]),\n",
       "  array([14729284881225,  3985945315286, 10922838355650,  7468280208774,\n",
       "         10846103248161]),\n",
       "  array([11307682770754, 14046295047943,  1461854993287, 15376440531200,\n",
       "          5892671538894]),\n",
       "  array([11976059385958,  6521141849124, 20508645308046,  3513530304009,\n",
       "          3097339933152]),\n",
       "  array([11898856649472, 15651917971184, 11731215852849,  6660407183360,\n",
       "         16405081956483]),\n",
       "  array([ 4379441359500,  9596845313139, 12613325112232, 15431704967714,\n",
       "          9130929232926]),\n",
       "  array([ 7233346161063,  2842128290268,  6859008978432, 12032068685582,\n",
       "          7724133396000]),\n",
       "  array([ 7694067516576,  8825001351972, 11805709586688, 17051920251040,\n",
       "          7484971520544]),\n",
       "  array([24292808251492,  8650370168384, 16235315040967, 13418082383451,\n",
       "         13547775818260]),\n",
       "  array([11109950010670,  4746205054587,  7672327128170,  6664606245836,\n",
       "         18575806632600]),\n",
       "  array([10049236411824,  9185846343504,  9203751528960,  4427209421763,\n",
       "         21744993318944]),\n",
       "  array([15190161105248, 18511308950248,  7808825759828, 10983759177456,\n",
       "          5637858077724]),\n",
       "  array([ 8878769073416,   997410654515,  7801043235900, 10590268770464,\n",
       "          8940273970600]),\n",
       "  array([ 6197135097098,  6086488888416, 15738255041696,  5237254140552,\n",
       "         19079801109540]),\n",
       "  array([ 6365753445850, 15531012608848,  9597281039080,  9060350123106,\n",
       "          9875319142320]),\n",
       "  array([12275051223288,  8698405424644,  6842949027600,  1752107929200,\n",
       "          6482172636410]),\n",
       "  array([18489775316992, 12694623849284,  7070494805414, 13494718538048,\n",
       "          8378881748061]),\n",
       "  array([12545964581337,  7504776756670,  6593997004427,  4732140356208,\n",
       "          6401393444984]),\n",
       "  array([ 7734281221359, 10988958512616,  8161534836736,  4549492283568,\n",
       "         11163559377848]),\n",
       "  array([13498586038730,  8243986998357,  6159185676720,  8089564549476,\n",
       "          7976716445615]),\n",
       "  array([ 9969933290310,  3846782423200, 11999689424931,  4174028462960,\n",
       "         11228196458070]),\n",
       "  array([17464913587072,  5349672015682,  6277591400640, 15589416491517,\n",
       "         12502515403664]),\n",
       "  array([ 9635537820360,  9189995038620,  6435045625473,  7396040706192,\n",
       "         11932098321230]),\n",
       "  array([16990517255168, 16629062856108,  7779478695424,  7925075016210,\n",
       "          7160772189891]),\n",
       "  array([13326993462266, 11487036808380, 12189050767528, 15255285292308,\n",
       "          2158518264868]),\n",
       "  array([17110827605700, 10046628445608,  1871681378336,  1315994140230,\n",
       "          9841714141992]),\n",
       "  array([ 5122293096492,  7760814551427, 14114532394200, 26254948613190,\n",
       "         10121340724726]),\n",
       "  array([ 7296180796700, 11011418698509,  4304082595638,  2992998886680,\n",
       "         12080025491004]),\n",
       "  array([17663819113237, 14381370108552, 11705131934100, 13109187418740,\n",
       "          7547970621429]),\n",
       "  array([12638533002435, 10818558759680,  6511869095592,  7503251659200,\n",
       "          7988819115616]),\n",
       "  array([5254005426060, 6604484415240, 2825237704914, 7884462977568,\n",
       "         7497871670626])])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e430b9-6e7b-4e0e-87f2-af560cbd38cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gml]",
   "language": "python",
   "name": "conda-env-gml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
