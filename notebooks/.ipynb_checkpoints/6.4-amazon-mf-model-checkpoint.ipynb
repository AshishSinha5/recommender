{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50882a56-0bdc-420e-85b6-424a40db99fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import itertools\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Any\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from typing import Dict, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b2814ca-876d-4018-93ba-e8c3444cfa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5bdf6dc-3ed2-4e70-a6ef-080c0e5c0408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/efs/fs1/miniconda3/envs/gml/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c2e943a-4429-4379-aea0-9ad399897dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a623f3f-64b5-4843-a579-5cecfdf5ba18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff390bb8570>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "662420af-9f05-49ef-bb6f-b92eb1b2d03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1+cu113\n",
      "torch.cuda.is_available() = True\n",
      "torch.cuda.device_count() = 1\n",
      "torch.cuda.get_device_name(0) = 'NVIDIA A10G'\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__) # Get PyTorch and CUDA version\n",
    "print(f\"{torch.cuda.is_available() = }\") # Check that CUDA works\n",
    "print(f\"{torch.cuda.device_count() = }\") # Check how many CUDA capable devices you have\n",
    "# Print device human readable names\n",
    "print(f\"{torch.cuda.get_device_name(0) = }\")\n",
    "# Add more lines with +1 like get_device_name(3), get_device_name(4) if you have more devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f7c37dc-b367-45a6-a11b-8b463c40ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4591bc95-71a6-4472-8a6c-2ff4c0798522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model: Any, model_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Saves model in gzip format\n",
    "\n",
    "    Args:\n",
    "        model: Model to be saved\n",
    "        model_path: Path to save model to\n",
    "        \n",
    "    Returns:\n",
    "        (None)\n",
    "    \"\"\"\n",
    "    import gzip\n",
    "    with gzip.open(model_path, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    print(f'Model saved to {model_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee658bc-dc25-4697-90d5-3057ff4b92fd",
   "metadata": {},
   "source": [
    "## Create the MF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80a81f20-efd4-4fbc-ba13-d9dc55ace4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularize_l2(array):\n",
    "    loss = torch.sum(array ** 2)\n",
    "    return loss\n",
    "\n",
    "class MF(nn.Module):\n",
    "    def __init__(self, emb_size, emb_dim, c_vector=1e-6):\n",
    "        super().__init__()\n",
    "        self.emb_size = emb_size # size of the dictionary of embeddings\n",
    "        self.emb_dim = emb_dim # size of each embedding vector\n",
    "        self.c_vector = c_vector\n",
    "        \n",
    "        # layers\n",
    "        self.embedding = nn.Embedding(emb_size, emb_dim)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "        # loss\n",
    "        self.bce = nn.BCELoss()\n",
    "        \n",
    "        print(f'Model initialized: {self}')\n",
    "        \n",
    "    def forward(self, product1, product2):\n",
    "        emb_product1 = self.embedding(product1)\n",
    "        emb_product2 = self.embedding(product2)\n",
    "        interaction = self.sig(torch.sum(emb_product1*emb_product2, dim = 1, dtype = torch.float))\n",
    "        return interaction\n",
    "    \n",
    "    \n",
    "    def loss(self, pred, label):\n",
    "        mf_loss = self.bce(pred, label)\n",
    "        \n",
    "        # L2 regularization\n",
    "        product_prior = regularize_l2(self.embedding.weight) * self.c_vector\n",
    "        \n",
    "        loss_total  = mf_loss + product_prior # loss + regularization \n",
    "        \n",
    "        return loss_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2c72bd-285b-4329-8eca-f4aaf1685907",
   "metadata": {},
   "source": [
    "## Test Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee543547-3620-4d69-8095-f79c8ab0a921",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized: MF(\n",
      "  (embedding): Embedding(1000, 12)\n",
      "  (sig): Sigmoid()\n",
      "  (bce): BCELoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MF(1000, 12).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cede1bfd-1ab9-4f93-8775-4d51582db829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6586, 0.9999], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.forward(torch.LongTensor([0,1]).to(device), torch.LongTensor([13,12]).to(device))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23171965-d63f-41ea-8a70-51af974d9330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5495, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss(pred, torch.FloatTensor([0,1]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8b50233-9b96-4201-a64f-8920ea1fb3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MF(\n",
       "  (embedding): Embedding(1000, 12)\n",
       "  (sig): Sigmoid()\n",
       "  (bce): BCELoss()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e02dedf-e5f2-459f-b72b-8ace2e121bd2",
   "metadata": {},
   "source": [
    "## Create the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0aaf16eb-a916-4d36-a440-a084f7077c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequences:\n",
    "    NEGATIVE_SAMPLE_TABLE_SIZE = 1e5\n",
    "    WINDOW = 5\n",
    "    \n",
    "    def __init__(self, sequence_path: str, val_path: str, subsample: float = 0.001, power: float = 0.75):\n",
    "        \"\"\"\n",
    "        Intialize the dataset object\n",
    "        \"\"\"\n",
    "        self.negative_idx = 0\n",
    "        self.n_unique_tokens = 0\n",
    "        \n",
    "        self.sequences = np.load(sequence_path).tolist()\n",
    "        self.n_sequences = len(self.sequences)\n",
    "        print(f'# Sequences = {self.n_sequences}')\n",
    "        \n",
    "        self.val = pd.read_csv(val_path)\n",
    "        print(f'# Validation data = {self.val.shape}')\n",
    "        \n",
    "        self.word_freq = self.get_word_freq()\n",
    "        \n",
    "        self.word2id, self.id2word = self.get_mapping_dicts()\n",
    "        self.add_val_product_to_mapping_dicts()\n",
    "        self.n_unique_tokens = len(self.word2id)\n",
    "        print(f'# Tokens = {self.n_unique_tokens}')\n",
    "        \n",
    "        sequence_file_name = Path(sequence_path).resolve().stem\n",
    "        save_model(self.word2id, f'../data/processed/{sequence_file_name}_word2id')\n",
    "        save_model(self.id2word, f'../data/processed/{sequence_file_name}_id2word')\n",
    "        \n",
    "        self.sequences = self.convert_sequence_to_id()\n",
    "        self.word_freq = self.convert_word_freq_to_id()\n",
    "        \n",
    "        self.discard_probs = self.get_discard_probs(sample = subsample)\n",
    "        \n",
    "        self.neg_table = self.get_negative_sample_table(power = power)\n",
    "        \n",
    "    def get_word_freq(self) -> Counter:\n",
    "        \"\"\"\n",
    "        Returns a dictionary of word frequencies\n",
    "        \"\"\"\n",
    "        \n",
    "        seq_flat = list(itertools.chain.from_iterable(self.sequences)) # flatten the array\n",
    "        \n",
    "        word_freq = Counter(seq_flat)\n",
    "        \n",
    "        return word_freq\n",
    "    \n",
    "    def get_mapping_dicts(self):\n",
    "        word2id = dict()\n",
    "        id2word = dict()\n",
    "        \n",
    "        wid = 0\n",
    "        for w,c in self.word_freq.items():\n",
    "            if wid == 0:\n",
    "                print(f\"{w = }, {c = }\")\n",
    "            word2id[w] = wid\n",
    "            id2word[wid] = w\n",
    "            wid += 1\n",
    "        \n",
    "        return word2id, id2word\n",
    "    \n",
    "    def add_val_product_to_mapping_dicts(self):\n",
    "        val_product_set = set(self.val['product1'].values).union(set(self.val['product2'].values))\n",
    "        \n",
    "        print(f'Size of word2id before adding val product : {len(self.word2id)}')\n",
    "        wid = max(self.word2id.values()) + 1\n",
    "        for w in val_product_set:\n",
    "            if w not in self.word2id:\n",
    "                self.word2id[w] = wid\n",
    "                self.id2word[wid] = w\n",
    "                wid +=1\n",
    "        \n",
    "        self.val = None # free up space\n",
    "        print(f'Size of the word2id after adding val product : {len(self.word2id)}')\n",
    "        \n",
    "                \n",
    "    def convert_sequence_to_id(self):\n",
    "        return np.vectorize(self.word2id.get)(self.sequences)\n",
    "    \n",
    "    def get_product_id(self, x):\n",
    "        return self.word2id.get(x, -1)\n",
    "    \n",
    "    def convert_word_freq_to_id(self):\n",
    "        return {self.word2id[k] : v for k ,v  in self.word_freq.items()}\n",
    "    \n",
    "    def get_discard_probs(self, sample = 0.001):\n",
    "        \"\"\"\n",
    "        Returns a dictionary of words and their associated discard probability, \n",
    "        word should ne discarded if np.random.rand() < probability\n",
    "        \"\"\"\n",
    "        \n",
    "        # convert to array\n",
    "        word_freq = np.array(list(self.word_freq.items()), dtype=np.float64)\n",
    "        \n",
    "        # convert to probability\n",
    "        word_freq[:, 1] = word_freq[:, 1] / word_freq[:, 1].sum()\n",
    "        \n",
    "        # perform subsampling \n",
    "        # http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/\n",
    "        word_freq[:, 1] = (np.sqrt(word_freq[:, 1]/ sample) + 1) * (sample / word_freq[:, 1]) \n",
    "        \n",
    "        # get dict \n",
    "        discard_probs = {int(k) : v for k, v in word_freq.tolist()}\n",
    "        \n",
    "        return discard_probs\n",
    "    \n",
    "    def get_negative_sample_table(self, power=0.75):\n",
    "        \"\"\"\n",
    "        Returns a table with size = NEGATIVE_SAMPLE_TABLE_SIZE of nagative samples which can be selected via indexing. \n",
    "        \"\"\"\n",
    "        \n",
    "        # COnvert to array \n",
    "        word_freq = np.array(list(self.word_freq.items()), dtype = np.float)\n",
    "        \n",
    "        # adjust the power\n",
    "        word_freq[:, 1] = word_freq[:, 1] ** power\n",
    "        \n",
    "        # Get probabilities\n",
    "        word_freq_sum = word_freq[:, 1].sum()\n",
    "        word_freq[:, 1] = word_freq[:, 1] / word_freq_sum\n",
    "        \n",
    "        # Multiply probabilities by sample table size\n",
    "        word_freq[:, 1] = np.round(word_freq[:, 1] * self.NEGATIVE_SAMPLE_TABLE_SIZE)\n",
    "        \n",
    "        # Convert to int \n",
    "        word_freq = word_freq.astype(int).tolist()\n",
    "        \n",
    "        # create the sample table\n",
    "        sample_table = [[tup[0]]*tup[1] for tup in tqdm(word_freq)] # repeating the index (wrod_id) by proportion of their frequency (more frequent words are more probable for sampling)\n",
    "        sample_table = np.array(list(itertools.chain.from_iterable(sample_table)))\n",
    "        np.random.shuffle(sample_table)\n",
    "\n",
    "        return sample_table\n",
    "        \n",
    "    \n",
    "    def get_pairs(self, idx, window = 5):\n",
    "        pairs = []\n",
    "        sequence = self.sequences[idx]\n",
    "        \n",
    "        for center_idx, node in enumerate(sequence):\n",
    "            for i in range(-window, window + 1):\n",
    "                context_idx = center_idx + i\n",
    "                if (context_idx > 0) and (context_idx < len(sequence)) and (node != sequence[context_idx]) and (np.random.rand() < self.discard_probs[sequence[context_idx]]):\n",
    "                    pairs.append((node, sequence[context_idx]))\n",
    "    \n",
    "        \n",
    "        return pairs\n",
    "    \n",
    "    def get_all_center_context_pair(self, window = 5) -> List[Tuple[int, int]]:\n",
    "        \"\"\"\n",
    "        Returns a list of tuples (center, context).\n",
    "        \n",
    "        Args: \n",
    "            window:\n",
    "            \n",
    "        Returns:\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        pairs = []\n",
    "        \n",
    "        for sequence in self.sequences:\n",
    "            for center_idx, node in enumerate(sequence):\n",
    "                context_idx = center_idx + i\n",
    "                if (0 <= context_idx < len(sequence)) \\\n",
    "                    and node != sequence[context_idx] \\\n",
    "                    and np.random.rand() < self.discard_probs[sequence[context_idx]]:\n",
    "                    pairs.append((node, sequence[context_idx]))\n",
    "                        \n",
    "            \n",
    "        return pairs\n",
    "    \n",
    "    \n",
    "    def get_negative_samples(self, context, sample_size = 5) -> np.array:\n",
    "        \"\"\"\n",
    "        Returns a list of negative samples, where len = sample_size.\n",
    "        \n",
    "        eg. if context is 12345 sample from \n",
    "        \n",
    "        Args:\n",
    "        \n",
    "            sample_size:\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        while True:\n",
    "            neg_sample = self.neg_table[self.negative_idx:self.negative_idx + sample_size]\n",
    "            \n",
    "            self.negative_idx = (self.negative_idx + sample_size) % len(self.neg_table)\n",
    "            \n",
    "            if len(neg_sample) != sample_size:\n",
    "                neg_sample = np.concatenate((neg_sample, \n",
    "                                             self.neg_table[:self.negative_idx]))\n",
    "                \n",
    "            \n",
    "            if not context in neg_sample:\n",
    "                return neg_sample    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd20f59d-8a87-4127-8514-965228b22d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequencesDataset(Dataset):\n",
    "    def __init__(self, sequences: Sequences, neg_sample_size = 5):\n",
    "        self.sequences = sequences\n",
    "        self.neg_sample_size = neg_sample_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.sequences.n_sequences\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        pairs = self.sequences.get_pairs(idx)\n",
    "        neg_samples = []\n",
    "        for center, context in pairs:\n",
    "            neg_samples.append(self.sequences.get_negative_samples(context))\n",
    "        \n",
    "        return pairs, neg_samples\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate(batches):\n",
    "        pairs_batch = [batch[0] for batch in batches]\n",
    "        neg_contexts_batch = [batch[1] for batch in batches]\n",
    "        \n",
    "        pairs_batch = list(itertools.chain.from_iterable(pairs_batch))\n",
    "        neg_contexts = list(itertools.chain.from_iterable(neg_contexts_batch))\n",
    "        \n",
    "        centers = [center for center, _ in pairs_batch]\n",
    "        contexts = [context for _, context in pairs_batch]\n",
    "        \n",
    "        return torch.LongTensor(centers), torch.LongTensor(contexts), torch.LongTensor(neg_contexts)\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate_for_mf(batches):\n",
    "        batch_list = []\n",
    "        \n",
    "        for batch in batches:\n",
    "            pairs = np.array(batch[0])\n",
    "            # print(f\"{pairs.shape=}\")\n",
    "            negs = np.array(batch[1])\n",
    "            # print(f\"{negs.shape=}\")\n",
    "            negs = np.vstack((pairs[:, 0].repeat(negs.shape[1]), negs.ravel())).T\n",
    "            # print(f\"{negs.shape=}\")\n",
    "            # print(negs)\n",
    "            pairs_arr = np.ones((pairs.shape[0], pairs.shape[1] + 1), dtype=int) # 2d\n",
    "            pairs_arr[:, :-1] = pairs\n",
    "            # print(f\"{pairs_arr.shape=}\")\n",
    "            negs_arr = np.zeros((negs.shape[0], negs.shape[1] + 1), dtype=int) # 2d\n",
    "            negs_arr[:, :-1] = negs\n",
    "            # print(f\"{negs_arr.shape=}\")\n",
    "            all_arr = np.vstack((pairs_arr, negs_arr)) # 2d\n",
    "            batch_list.append(all_arr)\n",
    "            \n",
    "        batch_array = np.vstack(batch_list)\n",
    "        \n",
    "        \n",
    "        return (torch.LongTensor(batch_array[:, 0]),torch.LongTensor(batch_array[:, 1]),\n",
    "                torch.FloatTensor(batch_array[:, 2]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d472d0-1a51-4e16-a5fa-b5c0076679cf",
   "metadata": {},
   "source": [
    "## Testing DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be9c1a5b-d337-466a-b6b9-a6f85a3398d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_path = '../data/processed/meta_Electronics_random_walks.npy'\n",
    "val_path = '../data/interim/meta_Electronics_edges_val.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "21cbe9d3-2b28-4640-acd3-bd9229f8d3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle = True\n",
    "emb_dim = 128\n",
    "epochs = 5\n",
    "initial_lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afbf2a5d-1ead-4fbb-a823-3e7eef303720",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Sequences = 4649780\n",
      "# Validation data = (1440998, 3)\n",
      "w = 'b00f37z8q6', c = 40\n",
      "Size of word2id before adding val product : 464978\n",
      "Size of the word2id after adding val product : 527314\n",
      "# Tokens = 527314\n",
      "Model saved to ../data/processed/meta_Electronics_random_walks_word2id\n",
      "Model saved to ../data/processed/meta_Electronics_random_walks_id2word\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51036/2275658908.py:113: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  word_freq = np.array(list(self.word_freq.items()), dtype = np.float)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 464978/464978 [00:00<00:00, 1015476.98it/s]\n"
     ]
    }
   ],
   "source": [
    "sequences = Sequences(read_path, val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7b5a38c-4335-42b7-9bf8-085b428e7a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences.word2id['b00f37z8q6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2716db26-d43d-4e46-a4a1-794344fd0c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences.word_freq[sequences.word2id['b00f37z8q6']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "663e825f-8ce7-48c6-b773-7524b7a30b35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = SequencesDataset(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "947e68c4-0e82-4775-b885-690d40c0de4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size = 32, shuffle = shuffle, num_workers = 32, collate_fn = dataset.collate_for_mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fa4f0aac-339c-4a6c-a70e-3d72f9a10797",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, 1),\n",
       "  (0, 2),\n",
       "  (0, 3),\n",
       "  (0, 4),\n",
       "  (0, 3),\n",
       "  (1, 2),\n",
       "  (1, 3),\n",
       "  (1, 4),\n",
       "  (1, 3),\n",
       "  (1, 5),\n",
       "  (2, 1),\n",
       "  (2, 3),\n",
       "  (2, 4),\n",
       "  (2, 3),\n",
       "  (2, 5),\n",
       "  (2, 6),\n",
       "  (3, 1),\n",
       "  (3, 2),\n",
       "  (3, 4),\n",
       "  (3, 5),\n",
       "  (3, 6),\n",
       "  (3, 5),\n",
       "  (4, 1),\n",
       "  (4, 2),\n",
       "  (4, 3),\n",
       "  (4, 3),\n",
       "  (4, 5),\n",
       "  (4, 6),\n",
       "  (4, 5),\n",
       "  (4, 7),\n",
       "  (3, 1),\n",
       "  (3, 2),\n",
       "  (3, 4),\n",
       "  (3, 5),\n",
       "  (3, 6),\n",
       "  (3, 5),\n",
       "  (3, 7),\n",
       "  (5, 1),\n",
       "  (5, 2),\n",
       "  (5, 3),\n",
       "  (5, 4),\n",
       "  (5, 3),\n",
       "  (5, 6),\n",
       "  (5, 7),\n",
       "  (6, 2),\n",
       "  (6, 3),\n",
       "  (6, 4),\n",
       "  (6, 3),\n",
       "  (6, 5),\n",
       "  (6, 5),\n",
       "  (6, 7),\n",
       "  (5, 3),\n",
       "  (5, 4),\n",
       "  (5, 3),\n",
       "  (5, 6),\n",
       "  (5, 7),\n",
       "  (7, 4),\n",
       "  (7, 3),\n",
       "  (7, 5),\n",
       "  (7, 6),\n",
       "  (7, 5)],\n",
       " [array([ 28412,  11156,  20672, 120964,  19066]),\n",
       "  array([308901, 105115,   2089,  33325,  22207]),\n",
       "  array([  5619,  35622,  34937,  53992, 138802]),\n",
       "  array([162353,   7150,  35164,  20126,  84868]),\n",
       "  array([32175, 45773, 15440, 11024, 97718]),\n",
       "  array([ 67569,  25303,   3173, 161681,  97372]),\n",
       "  array([40960, 19710, 65434, 28472,  3900]),\n",
       "  array([ 23990, 173031,  93102, 125488,  96357]),\n",
       "  array([108108,  21072,  76266,  46078,  16950]),\n",
       "  array([255972, 267790, 102096,  20467,  74571]),\n",
       "  array([ 6886, 37937, 68995, 30280, 42380]),\n",
       "  array([  1489, 159671, 105113,  31489,  32909]),\n",
       "  array([49557, 63181,  1427, 77851, 29094]),\n",
       "  array([21076, 24301,  5235,  3390,  2067]),\n",
       "  array([61110, 36808, 16984, 56668, 41738]),\n",
       "  array([10525, 35119, 37102, 35880, 16437]),\n",
       "  array([116065, 106932,  13522,  23564,  48015]),\n",
       "  array([ 38120,   5213, 368775, 157789,   7855]),\n",
       "  array([360685,  16506, 153331,  25527, 179319]),\n",
       "  array([38265, 81077, 40760, 82148, 11467]),\n",
       "  array([ 5022, 70151,  4899, 22671, 41879]),\n",
       "  array([169712,  66629,  79411,   4238, 188545]),\n",
       "  array([63988,  1236, 21589, 32756, 45235]),\n",
       "  array([ 39664,  51837, 334639,  31140,  24639]),\n",
       "  array([ 35915,  48974, 206806,  80638,     30]),\n",
       "  array([25027, 42152, 27471, 15990,  9942]),\n",
       "  array([ 37501, 158108,   4744,  40453,  37780]),\n",
       "  array([ 98863,  38646,  56033, 124214,  38953]),\n",
       "  array([99135, 33787, 99713,  5854,  8240]),\n",
       "  array([ 63030,  46944,  75431, 112356,   6907]),\n",
       "  array([29328, 77394,  3756, 34034, 25506]),\n",
       "  array([155677,  83316,   2446,    383,  78071]),\n",
       "  array([ 32610,   3224,    452, 112058, 120012]),\n",
       "  array([ 26266, 435478,  83790,   4814,  61265]),\n",
       "  array([ 10431,  23707, 151198,  24879,   2846]),\n",
       "  array([31028, 66953,  7217,  9465, 45940]),\n",
       "  array([  7041,  15636,  25624,  58650, 212804]),\n",
       "  array([ 68011, 209115,  43297,  34903,  12437]),\n",
       "  array([ 28616,  16776,  40153, 107089,   5831]),\n",
       "  array([ 74937, 229474,  10532,  85654, 118396]),\n",
       "  array([11340, 15424, 23149, 29430,  6982]),\n",
       "  array([20945, 13745, 30581, 16438, 23988]),\n",
       "  array([75839, 22993, 48812,  3034, 33519]),\n",
       "  array([  772, 23395, 34178, 55975,  6957]),\n",
       "  array([ 18631,   7732, 109274,   5092,  22211]),\n",
       "  array([55777, 57757, 85593, 87393, 35106]),\n",
       "  array([70547, 28807, 31934,  6194, 38545]),\n",
       "  array([304948, 117312,  35396, 171096,  31772]),\n",
       "  array([459973,  66773,  29731,   1873,    713]),\n",
       "  array([ 50058, 110223,  33869,  62930,   1363]),\n",
       "  array([23415, 26125, 31993, 54236, 17116]),\n",
       "  array([ 37012, 245223,  31248,  49453,  26798]),\n",
       "  array([ 46891,  47580,  78972, 175174,  16543]),\n",
       "  array([38776, 50787,  4788, 40725, 57792]),\n",
       "  array([28692, 86262, 24847, 29392,   639]),\n",
       "  array([55629,  3086, 38727, 47924, 37431]),\n",
       "  array([123004,  47810,     47,   4774,  27564]),\n",
       "  array([72387, 49725, 56329, 11001,  1617]),\n",
       "  array([ 73900, 108896,  57501,  71089,  76263]),\n",
       "  array([216223,  70938,  36469,  67621, 149652]),\n",
       "  array([ 53673,  18295,  72034, 111056,   2306])])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0] # returns a list of positive pairs and 5 negative sample for each context at idx i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e12cba0d-1a16-4eba-9f30-b5a337aa6e7c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 49132,  49132,  49132,  49132,  49132,  11948,  11948,  11948,  11948,\n",
      "         11948,   3090,   3090,   3090,   3090,   3090,   3090,  77342,  77342,\n",
      "         77342,  77342,  77342,  77342,  77342,  58658,  58658,  58658,  58658,\n",
      "         58658,  58658,  58658,  58658,  34740,  34740,  34740,  34740,  34740,\n",
      "         34740,  34740,  34740, 132340, 132340, 132340, 132340, 132340, 132340,\n",
      "        132340, 132340,   8870,   8870,   8870,   8870,   8870,   8870,   8870,\n",
      "         51148,  51148,  51148,  51148,  51148,  51148,  18668,  18668,  18668,\n",
      "         18668,  18668,  49132,  49132,  49132,  49132,  49132,  49132,  49132,\n",
      "         49132,  49132,  49132,  49132,  49132,  49132,  49132,  49132,  49132,\n",
      "         49132,  49132,  49132,  49132,  49132,  49132,  49132,  49132,  49132,\n",
      "         11948,  11948,  11948,  11948,  11948,  11948,  11948,  11948,  11948,\n",
      "         11948,  11948,  11948,  11948,  11948,  11948,  11948,  11948,  11948,\n",
      "         11948,  11948,  11948,  11948,  11948,  11948,  11948,   3090,   3090,\n",
      "          3090,   3090,   3090,   3090,   3090,   3090,   3090,   3090,   3090,\n",
      "          3090,   3090,   3090,   3090,   3090,   3090,   3090,   3090,   3090,\n",
      "          3090,   3090,   3090,   3090,   3090,   3090,   3090,   3090,   3090,\n",
      "          3090,  77342,  77342,  77342,  77342,  77342,  77342,  77342,  77342,\n",
      "         77342,  77342,  77342,  77342,  77342,  77342,  77342,  77342,  77342,\n",
      "         77342,  77342,  77342,  77342,  77342,  77342,  77342,  77342,  77342,\n",
      "         77342,  77342,  77342,  77342,  77342,  77342,  77342,  77342,  77342,\n",
      "         58658,  58658,  58658,  58658,  58658,  58658,  58658,  58658,  58658,\n",
      "         58658,  58658,  58658,  58658,  58658,  58658,  58658,  58658,  58658,\n",
      "         58658,  58658,  58658,  58658,  58658,  58658,  58658,  58658,  58658,\n",
      "         58658,  58658,  58658,  58658,  58658,  58658,  58658,  58658,  58658,\n",
      "         58658,  58658,  58658,  58658,  34740,  34740,  34740,  34740,  34740,\n",
      "         34740,  34740,  34740,  34740,  34740,  34740,  34740,  34740,  34740,\n",
      "         34740,  34740,  34740,  34740,  34740,  34740,  34740,  34740,  34740,\n",
      "         34740,  34740,  34740,  34740,  34740,  34740,  34740,  34740,  34740,\n",
      "         34740,  34740,  34740,  34740,  34740,  34740,  34740,  34740, 132340,\n",
      "        132340, 132340, 132340, 132340, 132340, 132340, 132340, 132340, 132340,\n",
      "        132340, 132340, 132340, 132340, 132340, 132340, 132340, 132340, 132340,\n",
      "        132340, 132340, 132340, 132340, 132340, 132340, 132340, 132340, 132340,\n",
      "        132340, 132340, 132340, 132340, 132340, 132340, 132340, 132340, 132340,\n",
      "        132340, 132340, 132340,   8870,   8870,   8870,   8870,   8870,   8870,\n",
      "          8870,   8870,   8870,   8870,   8870,   8870,   8870,   8870,   8870,\n",
      "          8870,   8870,   8870,   8870,   8870,   8870,   8870,   8870,   8870,\n",
      "          8870,   8870,   8870,   8870,   8870,   8870,   8870,   8870,   8870,\n",
      "          8870,   8870,  51148,  51148,  51148,  51148,  51148,  51148,  51148,\n",
      "         51148,  51148,  51148,  51148,  51148,  51148,  51148,  51148,  51148,\n",
      "         51148,  51148,  51148,  51148,  51148,  51148,  51148,  51148,  51148,\n",
      "         51148,  51148,  51148,  51148,  51148,  18668,  18668,  18668,  18668,\n",
      "         18668,  18668,  18668,  18668,  18668,  18668,  18668,  18668,  18668,\n",
      "         18668,  18668,  18668,  18668,  18668,  18668,  18668,  18668,  18668,\n",
      "         18668,  18668,  18668]), tensor([ 11948,   3090,  77342,  58658,  34740,   3090,  77342,  58658,  34740,\n",
      "        132340,  11948,  77342,  58658,  34740, 132340,   8870,  11948,   3090,\n",
      "         58658,  34740, 132340,   8870,  51148,  11948,   3090,  77342,  34740,\n",
      "        132340,   8870,  51148,  18668,  11948,   3090,  77342,  58658, 132340,\n",
      "          8870,  51148,  18668,  11948,   3090,  77342,  58658,  34740,   8870,\n",
      "         51148,  18668,   3090,  77342,  58658,  34740, 132340,  51148,  18668,\n",
      "         77342,  58658,  34740, 132340,   8870,  18668,  58658,  34740, 132340,\n",
      "          8870,  51148,  61614,  19577,   7040, 127332,  20282,  16876,  27713,\n",
      "         43063, 232139,  65302, 194666,   8049,  64592,  95205,  67994,  87810,\n",
      "         14078,  61639, 184137,  20604,  28798,  20051,  12419,  87973,  57494,\n",
      "         23022,  26800,  72851,  24199,  52255,   6295,   3479,  14600,  47422,\n",
      "          9698,  28494,  99066, 149514, 178461,  31124,   7179,  25416,  26525,\n",
      "         22727,   4357, 216270,  56174, 285310,  17121,  69377,  15618,  12664,\n",
      "        157659,  44660,  14464,  95912,  32682, 178496,  62918, 350598,  14994,\n",
      "          4320, 118499,   2356,   6726,  61099, 136470,  51145,  55768,  14629,\n",
      "         26514,  84285,  32587,  22558,    237,  71444,   4670,  89749,  17819,\n",
      "        106619,  11789,  35894,  16742,  43249,  37093,  15954,  11021,   1563,\n",
      "         58064,  28907,   3145,  89082,  10452,   1630, 352692,  15839,  13513,\n",
      "          2725,  81749,  16244,  21485,  56377,  28657,  15976,   9218,  11071,\n",
      "         39843, 112278,  23708,  33024, 233319,   5624,  24032,  61476,   5919,\n",
      "        125629,  28414,  94063, 117028,  78549, 133901,  62788,  52039,  63084,\n",
      "        132012, 173398,    267,  12794, 136037,  23592, 240285,  30561, 144305,\n",
      "          2278,  92633,  29417,    155,  24909,  28350,   6379,  27482, 131047,\n",
      "         65499,  22855,  52086,     46, 112445, 105824,  23090, 118586,  21419,\n",
      "         65048,     22,  81533,    302,  60095,  42519, 155080,  11567,  54321,\n",
      "        133087,  22220, 167749,  53599, 158639, 148476,  17273,   9999,  94504,\n",
      "         18048,  30529, 144090,  54383,  13702,  27963,  27183,  47322,  15881,\n",
      "         14403,   3395, 143765,  31526,  11901,    127,  29195,  41130,  63029,\n",
      "         12843,  43259, 100663,  75280,  23984,  19339,  88371,  43907,  24117,\n",
      "         60292,  14143, 437014,  12276,  75455,  64642, 140089,  18248,   3181,\n",
      "          9807,  22729, 255693,  90229,   4334,  27522,   2459, 134541,  97612,\n",
      "         85873,  43435,  35992,  50868,  10167,   3294,  69656,  27479,  71515,\n",
      "         53702,  53959, 161887, 112675,  67499,  31031,  41618,   3249,  24045,\n",
      "         17635,  24228,    209,  50886, 109850,    398,  43603,      9,   6074,\n",
      "         61489,   8254,  79308,  72820, 130132,   9158, 180323, 111621,  67824,\n",
      "         14933,  36384,   5151, 138668,  42416,  16222,  19711, 121363,  19102,\n",
      "         32831,  42582,  53359, 452997,  99715,  13176,  15240,  44925,   1035,\n",
      "         33826, 166426,  85292,   6770,  56209,  10487,   7540,  12323,   2257,\n",
      "         24776, 112863,  40405,   2401, 208362, 119729,  14266,  37252, 204798,\n",
      "          1660,  34690,  85219,  31814,  92668,  53758, 227890,  65516, 106936,\n",
      "        107742,  46801,  84473,  88972,  54968,   3487,   9584,  78582,  63650,\n",
      "         86084, 112285,  36146,   7856,  89690,  20119,  46909,  74685, 107160,\n",
      "         45609, 190828,  10978,  50423,  31195,  25808,  26177,  35799,  59968,\n",
      "        128841,  28969,  19343]), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))\n"
     ]
    }
   ],
   "source": [
    "for i, batches in enumerate(dataloader):\n",
    "    print(batches)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ce0f85-e776-406d-8e95-5c998b68df51",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4567e420-8220-447a-9f9a-981faf6a9cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product1</th>\n",
       "      <th>product2</th>\n",
       "      <th>edge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b00mmzfrhw</td>\n",
       "      <td>b01mzyoj76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b014lrkdwm</td>\n",
       "      <td>b071hb4bpr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b005l8vf3w</td>\n",
       "      <td>b00rkbb94s</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b01es8uwfm</td>\n",
       "      <td>b00bd8i3ei</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b00zw80dt8</td>\n",
       "      <td>b01eaiv5h4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     product1    product2  edge\n",
       "0  b00mmzfrhw  b01mzyoj76     1\n",
       "1  b014lrkdwm  b071hb4bpr     1\n",
       "2  b005l8vf3w  b00rkbb94s     1\n",
       "3  b01es8uwfm  b00bd8i3ei     1\n",
       "4  b00zw80dt8  b01eaiv5h4     1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prep sample val set\n",
    "val_df = pd.read_csv(val_path)\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b06e9ce7-3b5c-4686-ac7e-16c3df1e976d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440998, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "339bd645-b911-4b57-8a25-ae32271a2c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_PROP = 0.1\n",
    "val_samp = val_df.sample(frac=SAMPLE_PROP, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6542a9f-b141-4e7f-b1d1-54097d76e74b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144100, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_samp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0cb8240d-5073-49b4-b24a-4134a5273075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of validation samples: 144100\n"
     ]
    }
   ],
   "source": [
    "word2id_func = np.vectorize(sequences.get_product_id)\n",
    "val_samp['product1_id'] = word2id_func(val_samp['product1'].values)\n",
    "val_samp['product2_id'] = word2id_func(val_samp['product2'].values)\n",
    "val_samp = val_samp[(val_samp['product1_id'] > -1) & (val_samp['product2_id'] > -1)]  # Keep those with valid ID\n",
    "print('No. of validation samples: {}'.format(val_samp.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d207dbe4-48ed-4c7a-a37a-fe04128188c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "product1_id = val_samp['product1_id'].values\n",
    "product2_id = val_samp['product2_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d52bba5-63d3-4700-9637-5c1c22d659f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda, emb_dim: 128, epochs: 5, initial_lr: 0.01\n"
     ]
    }
   ],
   "source": [
    "print('Device: {}, emb_dim: {}, epochs: {}, initial_lr: {}'.format(device, emb_dim, epochs, initial_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "42b0daca-882b-43b2-8ca6-3918f7cbd302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized: MF(\n",
      "  (embedding): Embedding(527314, 128)\n",
      "  (sig): Sigmoid()\n",
      "  (bce): BCELoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "mf = MF(sequences.n_unique_tokens, emb_dim)\n",
    "mf = mf.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ad9e351-e710-44d7-8de9-a727b670bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(mf.parameters(), lr=initial_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76bea15-886e-4f11-a7eb-7d6512d8e5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Seq: 1,000/145,306, Loss: 0.7769, AUC-ROC: 0.5498, Lr: 0.009998\n",
      "Epoch: 0, Seq: 2,000/145,306, Loss: 0.7175, AUC-ROC: 0.5775, Lr: 0.009994\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "start_time = datetime.datetime.now()\n",
    "for epoch in range(epochs):\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, len(dataloader))\n",
    "    running_loss = 0\n",
    "    \n",
    "    for i, batches in enumerate(dataloader):\n",
    "        product1 = batches[0].to(device)\n",
    "        product2 = batches[1].to(device)\n",
    "        label = batches[2].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred = mf.forward(product1, product2)\n",
    "        loss = mf.loss(pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "        running_loss = running_loss * 0.9 + loss.item() * 0.1\n",
    "        \n",
    "        if (i > 0) and (i % 1000 == 0):\n",
    "            with torch.no_grad():\n",
    "                pred = mf.forward(torch.LongTensor(product1_id).to(device),\n",
    "                                  torch.LongTensor(product2_id).to(device))\n",
    "                \n",
    "                score = roc_auc_score(val_samp['edge'], pred.detach().cpu().numpy())\n",
    "       \n",
    "        \n",
    "            print(\"Epoch: {}, Seq: {:,}/{:,}, \" \\\n",
    "                  \"Loss: {:.4f}, AUC-ROC: {:.4f}, Lr: {:.6f}\".format(epoch, i, len(dataloader), running_loss,\n",
    "                                                                           score, optimizer.param_groups[0]['lr']))\n",
    "            results.append([epoch, i, running_loss, score])\n",
    "            running_loss = 0\n",
    "     \n",
    "    # save model\n",
    "    current_datetime = datetime.datetime.now().strftime('%Y-%m-%d-%H%M')\n",
    "    state_dict_path = ',,/models/mf_epoch_{}_{}.pt'.format(MODEL_PATH, epoch, current_datetime)\n",
    "    torch.save(mf.state_dict(), state_dict_path)\n",
    "    logger.info('Model state dict saved to {}'.format(state_dict_path))\n",
    "    \n",
    "end_time = datetime.datetime.now()               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e7d0ce-98a2-4adc-8696-6c4a7e4ea896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gml]",
   "language": "python",
   "name": "conda-env-gml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
