{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50882a56-0bdc-420e-85b6-424a40db99fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import itertools\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Any\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from typing import Dict, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b2814ca-876d-4018-93ba-e8c3444cfa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5bdf6dc-3ed2-4e70-a6ef-080c0e5c0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c2e943a-4429-4379-aea0-9ad399897dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a623f3f-64b5-4843-a579-5cecfdf5ba18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7496eeb5d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "662420af-9f05-49ef-bb6f-b92eb1b2d03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1\n",
      "torch.cuda.is_available() = True\n",
      "torch.cuda.device_count() = 7\n",
      "torch.cuda.get_device_name(1) = 'NVIDIA GeForce RTX 2080 Ti'\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__) # Get PyTorch and CUDA version\n",
    "print(f\"{torch.cuda.is_available() = }\") # Check that CUDA works\n",
    "print(f\"{torch.cuda.device_count() = }\") # Check how many CUDA capable devices you have\n",
    "# Print device human readable names\n",
    "print(f\"{torch.cuda.get_device_name(1) = }\")\n",
    "# Add more lines with +1 like get_device_name(3), get_device_name(4) if you have more devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f7c37dc-b367-45a6-a11b-8b463c40ca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4591bc95-71a6-4472-8a6c-2ff4c0798522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model: Any, model_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Saves model in gzip format\n",
    "\n",
    "    Args:\n",
    "        model: Model to be saved\n",
    "        model_path: Path to save model to\n",
    "        \n",
    "    Returns:\n",
    "        (None)\n",
    "    \"\"\"\n",
    "    import gzip\n",
    "    with gzip.open(model_path, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    print(f'Model saved to {model_path}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aee658bc-dc25-4697-90d5-3057ff4b92fd",
   "metadata": {},
   "source": [
    "## Create the MF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80a81f20-efd4-4fbc-ba13-d9dc55ace4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regularize_l2(array):\n",
    "    loss = torch.sum(array ** 2)\n",
    "    return loss\n",
    "\n",
    "class MF(nn.Module):\n",
    "    def __init__(self, emb_size, emb_dim, c_vector=1e-6):\n",
    "        super().__init__()\n",
    "        self.emb_size = emb_size # size of the dictionary of embeddings\n",
    "        self.emb_dim = emb_dim # size of each embedding vector\n",
    "        self.c_vector = c_vector\n",
    "        \n",
    "        # layers\n",
    "        self.embedding = nn.Embedding(emb_size, emb_dim)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "        # loss\n",
    "        self.bce = nn.BCELoss()\n",
    "        \n",
    "        print(f'Model initialized: {self}')\n",
    "        \n",
    "    def forward(self, product1, product2):\n",
    "        emb_product1 = self.embedding(product1)\n",
    "        emb_product2 = self.embedding(product2)\n",
    "        interaction = self.sig(torch.sum(emb_product1*emb_product2, dim = 1, dtype = torch.float))\n",
    "        return interaction\n",
    "    \n",
    "    \n",
    "    def loss(self, pred, label):\n",
    "        mf_loss = self.bce(pred, label)\n",
    "        \n",
    "        # L2 regularization\n",
    "        product_prior = regularize_l2(self.embedding.weight) * self.c_vector\n",
    "        \n",
    "        loss_total  = mf_loss + product_prior # loss + regularization \n",
    "        \n",
    "        return loss_total"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a2c72bd-285b-4329-8eca-f4aaf1685907",
   "metadata": {},
   "source": [
    "## Test Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee543547-3620-4d69-8095-f79c8ab0a921",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized: MF(\n",
      "  (embedding): Embedding(1000, 12)\n",
      "  (sig): Sigmoid()\n",
      "  (bce): BCELoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MF(1000, 12).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cede1bfd-1ab9-4f93-8775-4d51582db829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6586, 0.9999], device='cuda:1', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.forward(torch.LongTensor([0,1]).to(device), torch.LongTensor([13,12]).to(device))\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23171965-d63f-41ea-8a70-51af974d9330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5495, device='cuda:1', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss(pred, torch.FloatTensor([0,1]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8b50233-9b96-4201-a64f-8920ea1fb3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MF(\n",
       "  (embedding): Embedding(1000, 12)\n",
       "  (sig): Sigmoid()\n",
       "  (bce): BCELoss()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e02dedf-e5f2-459f-b72b-8ace2e121bd2",
   "metadata": {},
   "source": [
    "## Create the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0aaf16eb-a916-4d36-a440-a084f7077c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequences:\n",
    "    NEGATIVE_SAMPLE_TABLE_SIZE = 1e5\n",
    "    WINDOW = 5\n",
    "    \n",
    "    def __init__(self, sequence_path: str, val_path: str, subsample: float = 0.001, power: float = 0.75):\n",
    "        \"\"\"\n",
    "        Intialize the dataset object\n",
    "        \"\"\"\n",
    "        self.negative_idx = 0\n",
    "        self.n_unique_tokens = 0\n",
    "        \n",
    "        self.sequences = np.load(sequence_path).tolist()\n",
    "        self.n_sequences = len(self.sequences)\n",
    "        print(f'# Sequences = {self.n_sequences}')\n",
    "        \n",
    "        self.val = pd.read_csv(val_path)\n",
    "        print(f'# Validation data = {self.val.shape}')\n",
    "        \n",
    "        self.word_freq = self.get_word_freq()\n",
    "        \n",
    "        self.word2id, self.id2word = self.get_mapping_dicts()\n",
    "        self.add_val_product_to_mapping_dicts()\n",
    "        self.n_unique_tokens = len(self.word2id)\n",
    "        print(f'# Tokens = {self.n_unique_tokens}')\n",
    "        \n",
    "        sequence_file_name = Path(sequence_path).resolve().stem\n",
    "        save_model(self.word2id, f'../data/processed/{sequence_file_name}_word2id')\n",
    "        save_model(self.id2word, f'../data/processed/{sequence_file_name}_id2word')\n",
    "        \n",
    "        self.sequences = self.convert_sequence_to_id()\n",
    "        self.word_freq = self.convert_word_freq_to_id()\n",
    "        \n",
    "        self.discard_probs = self.get_discard_probs(sample = subsample)\n",
    "        \n",
    "        self.neg_table = self.get_negative_sample_table(power = power)\n",
    "        \n",
    "    def get_word_freq(self) -> Counter:\n",
    "        \"\"\"\n",
    "        Returns a dictionary of word frequencies\n",
    "        \"\"\"\n",
    "        \n",
    "        seq_flat = list(itertools.chain.from_iterable(self.sequences)) # flatten the array\n",
    "        \n",
    "        word_freq = Counter(seq_flat)\n",
    "        \n",
    "        return word_freq\n",
    "    \n",
    "    def get_mapping_dicts(self):\n",
    "        word2id = dict()\n",
    "        id2word = dict()\n",
    "        \n",
    "        wid = 0\n",
    "        for w,c in self.word_freq.items():\n",
    "            if wid == 0:\n",
    "                print(f\"{w = }, {c = }\")\n",
    "            word2id[w] = wid\n",
    "            id2word[wid] = w\n",
    "            wid += 1\n",
    "        \n",
    "        return word2id, id2word\n",
    "    \n",
    "    def add_val_product_to_mapping_dicts(self):\n",
    "        val_product_set = set(self.val['product1'].values).union(set(self.val['product2'].values))\n",
    "        \n",
    "        print(f'Size of word2id before adding val product : {len(self.word2id)}')\n",
    "        wid = max(self.word2id.values()) + 1\n",
    "        for w in val_product_set:\n",
    "            if w not in self.word2id:\n",
    "                self.word2id[w] = wid\n",
    "                self.id2word[wid] = w\n",
    "                wid +=1\n",
    "        \n",
    "        self.val = None # free up space\n",
    "        print(f'Size of the word2id after adding val product : {len(self.word2id)}')\n",
    "        \n",
    "                \n",
    "    def convert_sequence_to_id(self):\n",
    "        return np.vectorize(self.word2id.get)(self.sequences)\n",
    "    \n",
    "    def get_product_id(self, x):\n",
    "        return self.word2id.get(x, -1)\n",
    "    \n",
    "    def convert_word_freq_to_id(self):\n",
    "        return {self.word2id[k] : v for k ,v  in self.word_freq.items()}\n",
    "    \n",
    "    def get_discard_probs(self, sample = 0.001):\n",
    "        \"\"\"\n",
    "        Returns a dictionary of words and their associated discard probability, \n",
    "        word should ne discarded if np.random.rand() < probability\n",
    "        \"\"\"\n",
    "        \n",
    "        # convert to array\n",
    "        word_freq = np.array(list(self.word_freq.items()), dtype=np.float64)\n",
    "        \n",
    "        # convert to probability\n",
    "        word_freq[:, 1] = word_freq[:, 1] / word_freq[:, 1].sum()\n",
    "        \n",
    "        # perform subsampling \n",
    "        # http://mccormickml.com/2017/01/11/word2vec-tutorial-part-2-negative-sampling/\n",
    "        word_freq[:, 1] = (np.sqrt(word_freq[:, 1]/ sample) + 1) * (sample / word_freq[:, 1]) \n",
    "        \n",
    "        # get dict \n",
    "        discard_probs = {int(k) : v for k, v in word_freq.tolist()}\n",
    "        \n",
    "        return discard_probs\n",
    "    \n",
    "    def get_negative_sample_table(self, power=0.75):\n",
    "        \"\"\"\n",
    "        Returns a table with size = NEGATIVE_SAMPLE_TABLE_SIZE of nagative samples which can be selected via indexing. \n",
    "        \"\"\"\n",
    "        \n",
    "        # COnvert to array \n",
    "        word_freq = np.array(list(self.word_freq.items()), dtype = float)\n",
    "        \n",
    "        # adjust the power\n",
    "        word_freq[:, 1] = word_freq[:, 1] ** power\n",
    "        \n",
    "        # Get probabilities\n",
    "        word_freq_sum = word_freq[:, 1].sum()\n",
    "        word_freq[:, 1] = word_freq[:, 1] / word_freq_sum\n",
    "        \n",
    "        # Multiply probabilities by sample table size\n",
    "        word_freq[:, 1] = np.round(word_freq[:, 1] * self.NEGATIVE_SAMPLE_TABLE_SIZE)\n",
    "        \n",
    "        # Convert to int \n",
    "        word_freq = word_freq.astype(int).tolist()\n",
    "        \n",
    "        # create the sample table\n",
    "        sample_table = [[tup[0]]*tup[1] for tup in tqdm(word_freq)] # repeating the index (wrod_id) by proportion of their frequency (more frequent words are more probable for sampling)\n",
    "        sample_table = np.array(list(itertools.chain.from_iterable(sample_table)))\n",
    "        np.random.shuffle(sample_table)\n",
    "\n",
    "        return sample_table\n",
    "        \n",
    "    \n",
    "    def get_pairs(self, idx, window = 5):\n",
    "        pairs = []\n",
    "        sequence = self.sequences[idx]\n",
    "        \n",
    "        for center_idx, node in enumerate(sequence):\n",
    "            for i in range(-window, window + 1):\n",
    "                context_idx = center_idx + i\n",
    "                if (context_idx > 0) and (context_idx < len(sequence)) and (node != sequence[context_idx]) and (np.random.rand() < self.discard_probs[sequence[context_idx]]):\n",
    "                    pairs.append((node, sequence[context_idx]))\n",
    "    \n",
    "        \n",
    "        return pairs\n",
    "    \n",
    "    def get_all_center_context_pair(self, window = 5) -> List[Tuple[int, int]]:\n",
    "        \"\"\"\n",
    "        Returns a list of tuples (center, context).\n",
    "        \n",
    "        Args: \n",
    "            window:\n",
    "            \n",
    "        Returns:\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        pairs = []\n",
    "        \n",
    "        for sequence in self.sequences:\n",
    "            for center_idx, node in enumerate(sequence):\n",
    "                context_idx = center_idx + i\n",
    "                if (0 <= context_idx < len(sequence)) \\\n",
    "                    and node != sequence[context_idx] \\\n",
    "                    and np.random.rand() < self.discard_probs[sequence[context_idx]]:\n",
    "                    pairs.append((node, sequence[context_idx]))\n",
    "                        \n",
    "            \n",
    "        return pairs\n",
    "    \n",
    "    \n",
    "    def get_negative_samples(self, context, sample_size = 5) -> np.array:\n",
    "        \"\"\"\n",
    "        Returns a list of negative samples, where len = sample_size.\n",
    "        \n",
    "        eg. if context is 12345 sample from \n",
    "        \n",
    "        Args:\n",
    "        \n",
    "            sample_size:\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        while True:\n",
    "            neg_sample = self.neg_table[self.negative_idx:self.negative_idx + sample_size]\n",
    "            \n",
    "            self.negative_idx = (self.negative_idx + sample_size) % len(self.neg_table)\n",
    "            \n",
    "            if len(neg_sample) != sample_size:\n",
    "                neg_sample = np.concatenate((neg_sample, \n",
    "                                             self.neg_table[:self.negative_idx]))\n",
    "                \n",
    "            \n",
    "            if not context in neg_sample:\n",
    "                return neg_sample    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd20f59d-8a87-4127-8514-965228b22d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequencesDataset(Dataset):\n",
    "    def __init__(self, sequences: Sequences, neg_sample_size = 5):\n",
    "        self.sequences = sequences\n",
    "        self.neg_sample_size = neg_sample_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.sequences.n_sequences\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        pairs = self.sequences.get_pairs(idx)\n",
    "        neg_samples = []\n",
    "        for center, context in pairs:\n",
    "            neg_samples.append(self.sequences.get_negative_samples(context))\n",
    "        \n",
    "        return pairs, neg_samples\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate(batches):\n",
    "        pairs_batch = [batch[0] for batch in batches]\n",
    "        neg_contexts_batch = [batch[1] for batch in batches]\n",
    "        \n",
    "        pairs_batch = list(itertools.chain.from_iterable(pairs_batch))\n",
    "        neg_contexts = list(itertools.chain.from_iterable(neg_contexts_batch))\n",
    "        \n",
    "        centers = [center for center, _ in pairs_batch]\n",
    "        contexts = [context for _, context in pairs_batch]\n",
    "        \n",
    "        return torch.LongTensor(centers), torch.LongTensor(contexts), torch.LongTensor(neg_contexts)\n",
    "    \n",
    "    @staticmethod\n",
    "    def collate_for_mf(batches):\n",
    "        batch_list = []\n",
    "        \n",
    "        for batch in batches:\n",
    "            pairs = np.array(batch[0])\n",
    "            # print(f\"{pairs.shape=}\")\n",
    "            negs = np.array(batch[1])\n",
    "            # print(f\"{negs.shape=}\")\n",
    "            negs = np.vstack((pairs[:, 0].repeat(negs.shape[1]), negs.ravel())).T\n",
    "            # print(f\"{negs.shape=}\")\n",
    "            # print(negs)\n",
    "            pairs_arr = np.ones((pairs.shape[0], pairs.shape[1] + 1), dtype=int) # 2d\n",
    "            pairs_arr[:, :-1] = pairs\n",
    "            # print(f\"{pairs_arr.shape=}\")\n",
    "            negs_arr = np.zeros((negs.shape[0], negs.shape[1] + 1), dtype=int) # 2d\n",
    "            negs_arr[:, :-1] = negs\n",
    "            # print(f\"{negs_arr.shape=}\")\n",
    "            all_arr = np.vstack((pairs_arr, negs_arr)) # 2d\n",
    "            batch_list.append(all_arr)\n",
    "            \n",
    "        batch_array = np.vstack(batch_list)\n",
    "        \n",
    "        \n",
    "        return (torch.LongTensor(batch_array[:, 0]),torch.LongTensor(batch_array[:, 1]),\n",
    "                torch.FloatTensor(batch_array[:, 2]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83d472d0-1a51-4e16-a5fa-b5c0076679cf",
   "metadata": {},
   "source": [
    "## Testing DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be9c1a5b-d337-466a-b6b9-a6f85a3398d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_path = '../data/processed/meta_Electronics_random_walks.npy'\n",
    "val_path = '../data/interim/meta_Electronics_edges_val.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f71d494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle = True\n",
    "emb_dim = 128\n",
    "epochs = 4\n",
    "initial_lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afbf2a5d-1ead-4fbb-a823-3e7eef303720",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Sequences = 4649780\n",
      "# Validation data = (1440998, 3)\n",
      "w = 'b00f37z8q6', c = 34\n",
      "Size of word2id before adding val product : 464978\n",
      "Size of the word2id after adding val product : 527314\n",
      "# Tokens = 527314\n",
      "Model saved to ../data/processed/meta_Electronics_random_walks_word2id\n",
      "Model saved to ../data/processed/meta_Electronics_random_walks_id2word\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 464978/464978 [00:00<00:00, 822107.40it/s]\n"
     ]
    }
   ],
   "source": [
    "sequences = Sequences(read_path, val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7b5a38c-4335-42b7-9bf8-085b428e7a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences.word2id['b00f37z8q6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2716db26-d43d-4e46-a4a1-794344fd0c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences.word_freq[sequences.word2id['b00f37z8q6']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "663e825f-8ce7-48c6-b773-7524b7a30b35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = SequencesDataset(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "947e68c4-0e82-4775-b885-690d40c0de4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size = 32, shuffle = shuffle, num_workers = 32, collate_fn = dataset.collate_for_mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa4f0aac-339c-4a6c-a70e-3d72f9a10797",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(0, 1),\n",
       "  (0, 2),\n",
       "  (0, 3),\n",
       "  (0, 4),\n",
       "  (0, 5),\n",
       "  (1, 2),\n",
       "  (1, 3),\n",
       "  (1, 4),\n",
       "  (1, 5),\n",
       "  (1, 6),\n",
       "  (2, 1),\n",
       "  (2, 3),\n",
       "  (2, 4),\n",
       "  (2, 5),\n",
       "  (2, 6),\n",
       "  (2, 5),\n",
       "  (3, 1),\n",
       "  (3, 2),\n",
       "  (3, 4),\n",
       "  (3, 5),\n",
       "  (3, 6),\n",
       "  (3, 5),\n",
       "  (3, 7),\n",
       "  (4, 1),\n",
       "  (4, 2),\n",
       "  (4, 3),\n",
       "  (4, 5),\n",
       "  (4, 6),\n",
       "  (4, 5),\n",
       "  (4, 7),\n",
       "  (4, 8),\n",
       "  (5, 1),\n",
       "  (5, 2),\n",
       "  (5, 3),\n",
       "  (5, 4),\n",
       "  (5, 6),\n",
       "  (5, 7),\n",
       "  (5, 8),\n",
       "  (6, 1),\n",
       "  (6, 2),\n",
       "  (6, 3),\n",
       "  (6, 4),\n",
       "  (6, 5),\n",
       "  (6, 5),\n",
       "  (6, 7),\n",
       "  (6, 8),\n",
       "  (5, 2),\n",
       "  (5, 3),\n",
       "  (5, 4),\n",
       "  (5, 6),\n",
       "  (5, 7),\n",
       "  (5, 8),\n",
       "  (7, 3),\n",
       "  (7, 4),\n",
       "  (7, 5),\n",
       "  (7, 6),\n",
       "  (7, 5),\n",
       "  (7, 8),\n",
       "  (8, 4),\n",
       "  (8, 5),\n",
       "  (8, 6),\n",
       "  (8, 5),\n",
       "  (8, 7)],\n",
       " [array([ 21203,  49543,  84129, 210367,  96255]),\n",
       "  array([ 5267, 17155, 30655, 16774,  1448]),\n",
       "  array([28007, 15124, 55615,  4415,  7205]),\n",
       "  array([138020,  54213, 166846,  18281, 113226]),\n",
       "  array([58681, 57470, 50253, 49067, 20903]),\n",
       "  array([62660, 73547, 26671,   181, 17534]),\n",
       "  array([  5935,   7464,  14476,  35835, 111441]),\n",
       "  array([ 70160,  14564,  21844,  84662, 104714]),\n",
       "  array([ 4846, 55574, 52758,  1875, 24879]),\n",
       "  array([50067, 24408, 74507,  3856, 76439]),\n",
       "  array([ 41288,  57781,   7337, 128483,   8552]),\n",
       "  array([ 25401,  25980,   6008,  29183, 167695]),\n",
       "  array([31288, 52227, 17988, 11599, 40810]),\n",
       "  array([49599, 43880, 27371, 59256, 92011]),\n",
       "  array([173061,  39436, 134902,  30499,  23760]),\n",
       "  array([ 11627,   1734,  21870, 237848,  29839]),\n",
       "  array([76925,   245, 79343, 19672, 14843]),\n",
       "  array([ 98241,  96769,   1322, 116996, 259707]),\n",
       "  array([135835,   1265, 124548, 115893,   4939]),\n",
       "  array([14764, 82101, 59264,  3335, 10034]),\n",
       "  array([ 15099,  34469,  58424, 223228,  27585]),\n",
       "  array([ 88939, 106654, 135570, 105838,   5079]),\n",
       "  array([  4293,   2721,   2266,  73911, 121244]),\n",
       "  array([ 19458,  21843,  69602, 127023,    303]),\n",
       "  array([110003, 168273,  43180,  27889,  55790]),\n",
       "  array([269597,   1188,  41882,  37201,  28964]),\n",
       "  array([   266,  78836,  30085,  78855, 212064]),\n",
       "  array([36772, 53941, 95387, 58330,  1065]),\n",
       "  array([ 6563, 47615, 30391, 35236, 34209]),\n",
       "  array([ 14318,   1555,  30519,  14993, 169486]),\n",
       "  array([101406, 118099,  11837,  26001,  23826]),\n",
       "  array([ 82262, 135574,  54101, 119883,  64285]),\n",
       "  array([ 35838,  27501,  59769, 128475, 181026]),\n",
       "  array([ 86958, 106795,  10272,  28726,  87932]),\n",
       "  array([155580,  26846,    559, 150465,  57921]),\n",
       "  array([116368,  20431,  13227,  14138,  67951]),\n",
       "  array([  2462,  80497, 121590, 182970,  50840]),\n",
       "  array([ 11788, 102587,  86764,  19151,    771]),\n",
       "  array([ 8600, 26544, 55313, 61290, 38564]),\n",
       "  array([  4953, 162105,   8864,   2315, 154240]),\n",
       "  array([100283,   7940,  17020,  19324,  10444]),\n",
       "  array([ 19769,  16779,  92292,  33091, 117642]),\n",
       "  array([54260, 75596,  3268, 77895, 40559]),\n",
       "  array([ 28166,  21965,  10647, 101947,  85677]),\n",
       "  array([ 11075,  67746,  36157, 112743,   2167]),\n",
       "  array([73253, 10121,  7258, 10298,  2571]),\n",
       "  array([182086,  29644,  44776, 159077,  15143]),\n",
       "  array([ 9206, 54749, 12818, 11583, 62634]),\n",
       "  array([ 92870, 275478, 194419,  40647,   6323]),\n",
       "  array([ 41755,  26388,  93251, 166646,  46396]),\n",
       "  array([13123, 20621, 91904, 10276, 42425]),\n",
       "  array([57012, 85676, 50449, 82021, 13245]),\n",
       "  array([ 74930,    778, 445350, 190749,  91580]),\n",
       "  array([56860, 21775,  6588, 60136, 51255]),\n",
       "  array([76891, 25479, 47812, 27396, 14384]),\n",
       "  array([ 16482,  26438,   1033, 129927,   7434]),\n",
       "  array([47597, 65278, 93096, 27600, 50765]),\n",
       "  array([  6340,   5442, 143044,  25972,  39637]),\n",
       "  array([ 5012,  8813, 72774, 69539,  3715]),\n",
       "  array([20459, 33339, 70999, 74849,  3899]),\n",
       "  array([ 15192,  67226,  91825, 107761,   2248]),\n",
       "  array([11983,  1905,   122, 33084,  4936]),\n",
       "  array([236156,   9022,  23565,   1715,  26957])])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0] # returns a list of positive pairs and 5 negative sample for each context at idx i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e12cba0d-1a16-4eba-9f30-b5a337aa6e7c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 49132,  49132,  49132,  49132,  49132,  11948,  11948,  11948,  11948,\n",
      "         11948,   3090,   3090,   3090,   3090,   3090,   3090,  77342,  77342,\n",
      "         77342,  77342,  77342,  77342,  77342,  58658,  58658,  58658,  58658,\n",
      "         58658,  58658,  58658,  58658,  34740,  34740,  34740,  34740,  34740,\n",
      "         34740,  34740,  34740, 132340, 132340, 132340, 132340, 132340, 132340,\n",
      "        132340, 132340,   8870,   8870,   8870,   8870,   8870,   8870,   8870,\n",
      "         51148,  51148,  51148,  51148,  51148,  51148,  18668,  18668,  18668,\n",
      "         18668,  18668,  49132,  49132,  49132,  49132,  49132,  49132,  49132,\n",
      "         49132,  49132,  49132,  49132,  49132,  49132,  49132,  49132,  49132,\n",
      "         49132,  49132,  49132,  49132,  49132,  49132,  49132,  49132,  49132,\n",
      "         11948,  11948,  11948,  11948,  11948,  11948,  11948,  11948,  11948,\n",
      "         11948,  11948,  11948,  11948,  11948,  11948,  11948,  11948,  11948,\n",
      "         11948,  11948,  11948,  11948,  11948,  11948,  11948,   3090,   3090,\n",
      "          3090,   3090,   3090,   3090,   3090,   3090,   3090,   3090,   3090,\n",
      "          3090,   3090,   3090,   3090,   3090,   3090,   3090,   3090,   3090,\n",
      "          3090,   3090,   3090,   3090,   3090,   3090,   3090,   3090,   3090,\n",
      "          3090,  77342,  77342,  77342,  77342,  77342,  77342,  77342,  77342,\n",
      "         77342,  77342,  77342,  77342,  77342,  77342,  77342,  77342,  77342,\n",
      "         77342,  77342,  77342,  77342,  77342,  77342,  77342,  77342,  77342,\n",
      "         77342,  77342,  77342,  77342,  77342,  77342,  77342,  77342,  77342,\n",
      "         58658,  58658,  58658,  58658,  58658,  58658,  58658,  58658,  58658,\n",
      "         58658,  58658,  58658,  58658,  58658,  58658,  58658,  58658,  58658,\n",
      "         58658,  58658,  58658,  58658,  58658,  58658,  58658,  58658,  58658,\n",
      "         58658,  58658,  58658,  58658,  58658,  58658,  58658,  58658,  58658,\n",
      "         58658,  58658,  58658,  58658,  34740,  34740,  34740,  34740,  34740,\n",
      "         34740,  34740,  34740,  34740,  34740,  34740,  34740,  34740,  34740,\n",
      "         34740,  34740,  34740,  34740,  34740,  34740,  34740,  34740,  34740,\n",
      "         34740,  34740,  34740,  34740,  34740,  34740,  34740,  34740,  34740,\n",
      "         34740,  34740,  34740,  34740,  34740,  34740,  34740,  34740, 132340,\n",
      "        132340, 132340, 132340, 132340, 132340, 132340, 132340, 132340, 132340,\n",
      "        132340, 132340, 132340, 132340, 132340, 132340, 132340, 132340, 132340,\n",
      "        132340, 132340, 132340, 132340, 132340, 132340, 132340, 132340, 132340,\n",
      "        132340, 132340, 132340, 132340, 132340, 132340, 132340, 132340, 132340,\n",
      "        132340, 132340, 132340,   8870,   8870,   8870,   8870,   8870,   8870,\n",
      "          8870,   8870,   8870,   8870,   8870,   8870,   8870,   8870,   8870,\n",
      "          8870,   8870,   8870,   8870,   8870,   8870,   8870,   8870,   8870,\n",
      "          8870,   8870,   8870,   8870,   8870,   8870,   8870,   8870,   8870,\n",
      "          8870,   8870,  51148,  51148,  51148,  51148,  51148,  51148,  51148,\n",
      "         51148,  51148,  51148,  51148,  51148,  51148,  51148,  51148,  51148,\n",
      "         51148,  51148,  51148,  51148,  51148,  51148,  51148,  51148,  51148,\n",
      "         51148,  51148,  51148,  51148,  51148,  18668,  18668,  18668,  18668,\n",
      "         18668,  18668,  18668,  18668,  18668,  18668,  18668,  18668,  18668,\n",
      "         18668,  18668,  18668,  18668,  18668,  18668,  18668,  18668,  18668,\n",
      "         18668,  18668,  18668]), tensor([ 11948,   3090,  77342,  58658,  34740,   3090,  77342,  58658,  34740,\n",
      "        132340,  11948,  77342,  58658,  34740, 132340,   8870,  11948,   3090,\n",
      "         58658,  34740, 132340,   8870,  51148,  11948,   3090,  77342,  34740,\n",
      "        132340,   8870,  51148,  18668,  11948,   3090,  77342,  58658, 132340,\n",
      "          8870,  51148,  18668,  11948,   3090,  77342,  58658,  34740,   8870,\n",
      "         51148,  18668,   3090,  77342,  58658,  34740, 132340,  51148,  18668,\n",
      "         77342,  58658,  34740, 132340,   8870,  18668,  58658,  34740, 132340,\n",
      "          8870,  51148,  61614,  19577,   7040, 127332,  20282,  16876,  27713,\n",
      "         43063, 232139,  65302, 194666,   8049,  64592,  95205,  67994,  87810,\n",
      "         14078,  61639, 184137,  20604,  28798,  20051,  12419,  87973,  57494,\n",
      "         23022,  26800,  72851,  24199,  52255,   6295,   3479,  14600,  47422,\n",
      "          9698,  28494,  99066, 149514, 178461,  31124,   7179,  25416,  26525,\n",
      "         22727,   4357, 216270,  56174, 285310,  17121,  69377,  15618,  12664,\n",
      "        157659,  44660,  14464,  95912,  32682, 178496,  62918, 350598,  14994,\n",
      "          4320, 118499,   2356,   6726,  61099, 136470,  51145,  55768,  14629,\n",
      "         26514,  84285,  32587,  22558,    237,  71444,   4670,  89749,  17819,\n",
      "        106619,  11789,  35894,  16742,  43249,  37093,  15954,  11021,   1563,\n",
      "         58064,  28907,   3145,  89082,  10452,   1630, 352692,  15839,  13513,\n",
      "          2725,  81749,  16244,  21485,  56377,  28657,  15976,   9218,  11071,\n",
      "         39843, 112278,  23708,  33024, 233319,   5624,  24032,  61476,   5919,\n",
      "        125629,  28414,  94063, 117028,  78549, 133901,  62788,  52039,  63084,\n",
      "        132012, 173398,    267,  12794, 136037,  23592, 240285,  30561, 144305,\n",
      "          2278,  92633,  29417,    155,  24909,  28350,   6379,  27482, 131047,\n",
      "         65499,  22855,  52086,     46, 112445, 105824,  23090, 118586,  21419,\n",
      "         65048,     22,  81533,    302,  60095,  42519, 155080,  11567,  54321,\n",
      "        133087,  22220, 167749,  53599, 158639, 148476,  17273,   9999,  94504,\n",
      "         18048,  30529, 144090,  54383,  13702,  27963,  27183,  47322,  15881,\n",
      "         14403,   3395, 143765,  31526,  11901,    127,  29195,  41130,  63029,\n",
      "         12843,  43259, 100663,  75280,  23984,  19339,  88371,  43907,  24117,\n",
      "         60292,  14143, 437014,  12276,  75455,  64642, 140089,  18248,   3181,\n",
      "          9807,  22729, 255693,  90229,   4334,  27522,   2459, 134541,  97612,\n",
      "         85873,  43435,  35992,  50868,  10167,   3294,  69656,  27479,  71515,\n",
      "         53702,  53959, 161887, 112675,  67499,  31031,  41618,   3249,  24045,\n",
      "         17635,  24228,    209,  50886, 109850,    398,  43603,      9,   6074,\n",
      "         61489,   8254,  79308,  72820, 130132,   9158, 180323, 111621,  67824,\n",
      "         14933,  36384,   5151, 138668,  42416,  16222,  19711, 121363,  19102,\n",
      "         32831,  42582,  53359, 452997,  99715,  13176,  15240,  44925,   1035,\n",
      "         33826, 166426,  85292,   6770,  56209,  10487,   7540,  12323,   2257,\n",
      "         24776, 112863,  40405,   2401, 208362, 119729,  14266,  37252, 204798,\n",
      "          1660,  34690,  85219,  31814,  92668,  53758, 227890,  65516, 106936,\n",
      "        107742,  46801,  84473,  88972,  54968,   3487,   9584,  78582,  63650,\n",
      "         86084, 112285,  36146,   7856,  89690,  20119,  46909,  74685, 107160,\n",
      "         45609, 190828,  10978,  50423,  31195,  25808,  26177,  35799,  59968,\n",
      "        128841,  28969,  19343]), tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))\n"
     ]
    }
   ],
   "source": [
    "for i, batches in enumerate(dataloader):\n",
    "    print(batches)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51ce0f85-e776-406d-8e95-5c998b68df51",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4567e420-8220-447a-9f9a-981faf6a9cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product1</th>\n",
       "      <th>product2</th>\n",
       "      <th>edge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b00mmzfrhw</td>\n",
       "      <td>b01mzyoj76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b014lrkdwm</td>\n",
       "      <td>b071hb4bpr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b005l8vf3w</td>\n",
       "      <td>b00rkbb94s</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b01es8uwfm</td>\n",
       "      <td>b00bd8i3ei</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b00zw80dt8</td>\n",
       "      <td>b01eaiv5h4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     product1    product2  edge\n",
       "0  b00mmzfrhw  b01mzyoj76     1\n",
       "1  b014lrkdwm  b071hb4bpr     1\n",
       "2  b005l8vf3w  b00rkbb94s     1\n",
       "3  b01es8uwfm  b00bd8i3ei     1\n",
       "4  b00zw80dt8  b01eaiv5h4     1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prep sample val set\n",
    "val_df = pd.read_csv(val_path)\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b06e9ce7-3b5c-4686-ac7e-16c3df1e976d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440998, 3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "339bd645-b911-4b57-8a25-ae32271a2c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_PROP = 0.1\n",
    "val_samp = val_df.sample(frac=SAMPLE_PROP, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6542a9f-b141-4e7f-b1d1-54097d76e74b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144100, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_samp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0cb8240d-5073-49b4-b24a-4134a5273075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of validation samples: 144100\n"
     ]
    }
   ],
   "source": [
    "word2id_func = np.vectorize(sequences.get_product_id)\n",
    "val_samp['product1_id'] = word2id_func(val_samp['product1'].values)\n",
    "val_samp['product2_id'] = word2id_func(val_samp['product2'].values)\n",
    "val_samp = val_samp[(val_samp['product1_id'] > -1) & (val_samp['product2_id'] > -1)]  # Keep those with valid ID\n",
    "print('No. of validation samples: {}'.format(val_samp.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d207dbe4-48ed-4c7a-a37a-fe04128188c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "product1_id = val_samp['product1_id'].values\n",
    "product2_id = val_samp['product2_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9d52bba5-63d3-4700-9637-5c1c22d659f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda, emb_dim: 128, epochs: 4, initial_lr: 0.01\n"
     ]
    }
   ],
   "source": [
    "print('Device: {}, emb_dim: {}, epochs: {}, initial_lr: {}'.format(device, emb_dim, epochs, initial_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42b0daca-882b-43b2-8ca6-3918f7cbd302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized: MF(\n",
      "  (embedding): Embedding(527314, 128)\n",
      "  (sig): Sigmoid()\n",
      "  (bce): BCELoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize model\n",
    "mf = MF(sequences.n_unique_tokens, emb_dim)\n",
    "mf = mf.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ad9e351-e710-44d7-8de9-a727b670bb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(mf.parameters(), lr=initial_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e76bea15-886e-4f11-a7eb-7d6512d8e5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
      "Wall time: 9.06 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "results = []\n",
    "start_time = datetime.datetime.now()\n",
    "for epoch in range(epochs):\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, len(dataloader))\n",
    "    running_loss = 0\n",
    "    \n",
    "    for i, batches in enumerate(dataloader):\n",
    "        product1 = batches[0].to(device)\n",
    "        product2 = batches[1].to(device)\n",
    "        label = batches[2].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred = mf.forward(product1, product2)\n",
    "        loss = mf.loss(pred, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "        running_loss = running_loss * 0.9 + loss.item() * 0.1\n",
    "        \n",
    "        if (i > 0) and (i % 1000 == 0):\n",
    "            with torch.no_grad():\n",
    "                pred = mf.forward(torch.LongTensor(product1_id).to(device),\n",
    "                                  torch.LongTensor(product2_id).to(device))\n",
    "                \n",
    "                score = roc_auc_score(val_samp['edge'], pred.detach().cpu().numpy())\n",
    "       \n",
    "        \n",
    "            print(\"Epoch: {}, Seq: {:,}/{:,}, \" \\\n",
    "                  \"Loss: {:.4f}, AUC-ROC: {:.4f}, Lr: {:.6f}\".format(epoch, i, len(dataloader), running_loss,\n",
    "                                                                           score, optimizer.param_groups[0]['lr']))\n",
    "            results.append([epoch, i, running_loss, score])\n",
    "            running_loss = 0\n",
    "     \n",
    "    # save model\n",
    "    current_datetime = datetime.datetime.now().strftime('%Y-%m-%d-%H%M')\n",
    "    state_dict_path = '../models/meta_electronics_mf_epoch_{}_{}.pt'.format(epoch, current_datetime)\n",
    "    torch.save(mf.state_dict(), state_dict_path)\n",
    "    print('Model state dict saved to {}'.format(state_dict_path))\n",
    "    \n",
    "end_time = datetime.datetime.now()               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e7d0ce-98a2-4adc-8696-6c4a7e4ea896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
